{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "from osgeo import gdal\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.transform as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotif_dsm_file =  '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/mapping/orthomosaics/observation088_dsm.tif'\n",
    "geotif_image_file = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/mapping/orthomosaics/observation088_transparent_mosaic_group1.tif'\n",
    "dsm_gtif = gdal.Open(geotif_dsm_file)\n",
    "image_gtif = gdal.Open(geotif_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f40d0b6b358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm = dsm_gtif.GetRasterBand(1).ReadAsArray()\n",
    "dsm_ave = np.min(dsm[dsm!= -10000])\n",
    "dsm = np.where(dsm == -10000, dsm_ave, dsm)\n",
    "elevation_r = dsm\n",
    "\n",
    "bands = []\n",
    "for band_num in range(1, 4):\n",
    "    srcband = image_gtif.GetRasterBand(band_num)\n",
    "    a = srcband.ReadAsArray()\n",
    "    bands.append(a)\n",
    "image_map = np.stack(bands, 2)\n",
    "plt.figure()\n",
    "plt.imshow(image_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_map_image= transform.rescale(image_map, .1, multichannel=True, mode='reflect', anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig2data ( fig ):\n",
    "    \"\"\"\n",
    "    @brief Convert a Matplotlib figure to a 4D numpy array with RGBA channels and return it\n",
    "    @param fig a matplotlib figure\n",
    "    @return a numpy 3D array of RGBA values\n",
    "    \"\"\"\n",
    "    # draw the renderer\n",
    "    fig.canvas.draw()\n",
    " \n",
    "    # Get the RGBA buffer from the figure\n",
    "    w,h = fig.canvas.get_width_height()\n",
    "    buf = np.fromstring(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
    "    buf.shape = (h, w, 4)\n",
    " \n",
    "    # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode\n",
    "    buf = np.roll(buf, 3, axis=2)\n",
    "    return cv2.cvtColor(buf, cv2.COLOR_RGBA2BGR)\n",
    "\n",
    "def job(feed_dict):\n",
    "\n",
    "    idx = feed_dict['idx']\n",
    "    frame = feed_dict['frame']\n",
    "    positions = feed_dict['positions']\n",
    "#     frame = frame[40:160,20:140,1]\n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(10,10))\n",
    "    ax1.imshow(frame, cmap='gray', interpolation='none', aspect='auto')\n",
    "    for position_ind in range(positions.shape[0]):\n",
    "        ax1.plot(positions[position_ind][0], positions[position_ind][1])\n",
    "    ax1.axis('off')\n",
    "    output_frame = fig2data(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return output_frame\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "out = cv2.VideoWriter('map_animation.mp4', fourcc, 30.0, (720,360))\n",
    "\n",
    "batch_size=50\n",
    "start_idx = 0\n",
    "end_idx = 500\n",
    "frame_indexes = np.arange(start_idx, end_idx)\n",
    "\n",
    "test_positions = np.random.rand(end_idx, 10, 2) * background_map_image.shape[:2]\n",
    "\n",
    "main_loop_idx = 0\n",
    "pool = Parallel(-1)\n",
    "while main_loop_idx*batch_size < end_idx-start_idx:\n",
    "#for i in range(1):\n",
    "    feed_dicts = [{'frame':background_map_image, 'idx':frame_indexes[idx], 'positions': test_positions[idx]} for idx in zip(np.arange(main_loop_idx*batch_size, (main_loop_idx+1)*batch_size))]\n",
    "    output_frames = pool.process(job, feed_dicts)\n",
    "    out.write_batch(output_frames)\n",
    "    print(main_loop_idx*batch_size)\n",
    "    main_loop_idx += 1\n",
    "pool.close()    \n",
    "out.release()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.rand(500, 10, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_new = r * background_map_image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "out = cv2.VideoWriter('map_animation.mp4', fourcc, 30.0, (720,360))\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
