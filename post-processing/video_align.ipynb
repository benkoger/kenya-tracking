{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images to be aligned\n",
    "im1 =  cv2.imread('/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/raw_frames/scare_clips/PZ/APR05_2018_I_DJI_0012/APR05_2018_I_DJI_0012_11342.jpg' )\n",
    "im2 =  cv2.imread('/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/raw_frames/scare_clips/PZ/APR05_2018_I_DJI_0012/APR05_2018_I_DJI_0012_11344.jpg' )\n",
    "\n",
    "root  = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/raw_frames/scare_clips/PZ/APR05_2018_I_DJI_0012/APR05_2018_I_DJI_0012_113'\n",
    "    \n",
    "ims_file = [root + str(36 + ind*2) + '.jpg' for ind in range(10)] \n",
    "ims = [cv2.imread(file) for file in ims_file]\n",
    "\n",
    "down_sampling = 2\n",
    "    \n",
    "new_shape = (int(ims[0].shape[1]/down_sampling), int(ims[0].shape[0]/down_sampling)) \n",
    "\n",
    "# im1 = cv2.resize(im1, new_shape, interpolation=cv2.INTER_LINEAR)\n",
    "# im2 = cv2.resize(im2, new_shape, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "ims_small = [cv2.resize(im, new_shape, interpolation=cv2.INTER_LINEAR) for im in ims]\n",
    "\n",
    "im_shape = ims_small[0].shape\n",
    "\n",
    "\n",
    "\n",
    "# im1 = im1[:, width_start:-width_start]\n",
    "# im2 = im2[:, width_start:-width_start]\n",
    "\n",
    "\n",
    "\n",
    "# # Convert images to grayscale\n",
    "# im1_gray = cv2.cvtColor(im1,cv2.COLOR_BGR2GRAY)\n",
    "# im2_gray = cv2.cvtColor(im2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ims_green = [im[:, :, :] for im in ims_small]\n",
    "# # Find size of image1\n",
    "# sz = im1.shape\n",
    " \n",
    "# # Define the motion model\n",
    "# warp_mode = cv2.MOTION_EUCLIDEAN\n",
    " \n",
    "# # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "# if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "#     warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "# else :\n",
    "#     warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    " \n",
    "#  # Specify the number of iterations.\n",
    "# number_of_iterations = 3000;\n",
    " \n",
    "# # Specify the threshold of the increment\n",
    "# # in the correlation coefficient between two iterations\n",
    "# termination_eps = 1e-10;\n",
    " \n",
    "# # Define termination criteria\n",
    "# criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "warps = []\n",
    "aligned = []\n",
    "total_warp = np.eye(3)\n",
    "\n",
    "\n",
    "\n",
    "for im_ind, im in enumerate(ims_green[:-1]):\n",
    "    warp_matrix = cv2.estimateRigidTransform(im, ims_green[im_ind + 1], fullAffine=False) \n",
    "    aligned.append(cv2.warpAffine(ims_green[im_ind + 1], warp_matrix, (im_shape[1], im_shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP))\n",
    "    warps.append(warp_matrix)\n",
    "    warp_matrix = np.vstack((warp_matrix, np.array([0,0,1]))) \n",
    "    total_warp = np.matmul(total_warp, warp_matrix)\n",
    "    \n",
    "total_warp = total_warp[:2,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.9568    ,   -0.29311721,  202.80828144],\n",
       "       [   0.29311721,    0.9568    , -281.61435939]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[   0.95607778,   -0.29434366,  183.41945556],\n",
    "       [   0.29434366,    0.95607778, -140.99255209]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_im = ims_green[-1]\n",
    "for warp in warps[::-1]:\n",
    "    last_im = cv2.warpAffine(last_im, warp, (im_shape[1], im_shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "second_go = cv2.warpAffine(ims_green[-1], total_warp, (im_shape[1], im_shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "cv2.imshow(\"Aligned Image 2 \", ims_green[0] - second_go)\n",
    "cv2.imshow(\"im0\", ims_green[0])\n",
    "cv2.imshow(\"econd_go\", second_go)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996518496808582\n"
     ]
    }
   ],
   "source": [
    "# Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "(cc, warp_matrix) = cv2.findTransformECC (im1_gray,im2_gray,warp_matrix, warp_mode, criteria)\n",
    "print(cc)\n",
    " \n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "    # Use warpPerspective for Homography \n",
    "    im2_aligned = cv2.warpPerspective (im2, warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "else :\n",
    "    # Use warpAffine for Translation, Euclidean and Affine\n",
    "    im2_aligned = cv2.warpAffine(im2, warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Show final results\n",
    "cv2.imshow(\"Image 1\", im1 - im2)\n",
    "cv2.imshow(\"Image 2\", im1 - im2_aligned)\n",
    "cv2.imshow(\"Aligned Image 2\", im2_aligned)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "0.5363452434539795\n"
     ]
    }
   ],
   "source": [
    "warp_matrix = cv2.estimateRigidTransform(im1_gray, im2_gray, fullAffine=False) \n",
    "im2_aligned_2 = cv2.warpAffine(im2, warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Show final results\n",
    "cv2.imshow(\"Image 1\", im1 - im2)\n",
    "cv2.imshow(\"Image 2\", im1 - im2_aligned)\n",
    "cv2.imshow(\"Aligned Image 2\", im2_aligned)\n",
    "cv2.imshow(\"Image 1a\", im1 - im2)\n",
    "cv2.imshow(\"Image 2a\", im1 - im2_aligned_2)\n",
    "cv2.imshow(\"Aligned Image 2a\", im2_aligned_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.9995621 ,  -0.03279349,  17.95482768],\n",
       "       [  0.03279349,   0.9995621 , -18.16499636]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029595028523110984\n",
      "0.03279937003053213\n"
     ]
    }
   ],
   "source": [
    "print(np.arccos(warp_matrix[0,0]))\n",
    "print(np.arcsin(warp_matrix[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
