{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    image_array = np.array(image.getdata())\n",
    "    try:\n",
    "        image_array = image_array.reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_frame_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time\n",
    "\n",
    "class ImageReader:\n",
    "    def __init__(self, image_file_list, queue_size=100):\n",
    "        # initialize the file video stream along with the boolean\n",
    "        # used to indicate if the thread should be stopped or not\n",
    "        self.image_files = image_file_list\n",
    "        self.total_frames = len(image_file_list)\n",
    "        self.stopped = False\n",
    "        # initialize the queue used to store frames read from\n",
    "        # the video file\n",
    "        self.Q = Queue(maxsize=queue_size)\n",
    "\n",
    "    def start(self):\n",
    "        # start a thread to read frames from the file video stream\n",
    "        t = Thread(target=self.update, args=())\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "        time.sleep(1)\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        # keep looping infinitely\n",
    "        frame_num = starting_frame_num\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the\n",
    "            # thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            # otherwise, ensure the queue has room in it\n",
    "            if not self.Q.full():\n",
    "                # read the next frame from the file\n",
    "                image_np = cv2.imread(self.image_files[frame_num])\n",
    "                # add the frame to the queue\n",
    "                self.Q.put([image_np, self.image_files[frame_num]])\n",
    "                \n",
    "                frame_num += 1\n",
    "                \n",
    "                if frame_num >= self.total_frames:\n",
    "                    self.stop()\n",
    "                    return\n",
    "                \n",
    "                \n",
    "\n",
    "    def read(self):\n",
    "        # return next frame in the queue\n",
    "        return self.Q.get()\n",
    "\n",
    "    def read_batch(self, n_frames, asarray=False):\n",
    "        frames = []\n",
    "        for idx in range(n_frames):\n",
    "            frames.append(self.read())\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def more(self):\n",
    "        # return True if there are still frames in the queue\n",
    "        return self.Q.qsize() > 0\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        print('stopping')\n",
    "        self.stopped = True\n",
    "        \n",
    "    def close(self):\n",
    "        self.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import sys\n",
    "import time\n",
    "\n",
    "class VideoWriter:\n",
    "    def __init__(self, queue_size=100, timeout=3, frame_width=0, frame_height=0, video_out_file=None):\n",
    "        # initialize the file video stream along with the boolean\n",
    "        # used to indicate if the thread should be stopped or not\n",
    "        self.queue_size = queue_size\n",
    "        self.timeout = timeout\n",
    "        self.stopped = False\n",
    "        self.frame_width = frame_width\n",
    "        self.frame_height = frame_height\n",
    "        # initialize the queue used to store frames read from\n",
    "        # the video file\n",
    "        self.Q = Queue(maxsize=queue_size)\n",
    "        self.video_out_file = video_out_file\n",
    "\n",
    "    def start(self):\n",
    "        \n",
    "#         fourcc = cv2.VideoWriter_fourcc(*'mjpg')\n",
    "#         self.out = cv2.VideoWriter(filename=self.video_out_file, fourcc=fourcc, fps=30, \n",
    "#                               frameSize=(frame_width, frame_height), isColor=True)\n",
    "        # start a thread to read frames from the file video stream\n",
    "        self.t = Thread(target=self.write, args=())\n",
    "        self.t.daemon = True\n",
    "        self.t.start()\n",
    "        time.sleep(1)\n",
    "        return self\n",
    "\n",
    "    def write(self):\n",
    "        # keep looping infinitely\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the\n",
    "            # thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            # otherwise, ensure the queue has room in it\n",
    "            if not self.Q.empty():\n",
    "                frame, frame_file = self.Q.get()\n",
    "#                 self.out.write(frame)\n",
    "                file_name = os.path.basename(frame_file)\n",
    "                frame_new_file = os.path.join(self.video_out_file, file_name)\n",
    "                cv2.imwrite(frame_new_file, frame)\n",
    "                # add the frame to the queue\n",
    "            else:\n",
    "                time.sleep(self.timeout)\n",
    "    \n",
    "    def add_frame(self, frame):\n",
    "        self.Q.put(frame)\n",
    "                \n",
    "                \n",
    "\n",
    "    def flush(self):\n",
    "        while not self.Q.empty():\n",
    "#             frame = self.Q.get()\n",
    "#             self.out.write(frame)\n",
    "            frame, frame_file = self.Q.get()\n",
    "#                 self.out.write(frame)\n",
    "            file_name = os.path.basename(frame_file)\n",
    "            frame_new_file = os.path.join(self.video_out_file, file_name)\n",
    "            cv2.imwrite(frame_new_file, frame)\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        print('stopping')\n",
    "        self.stopped = True\n",
    "        self.t.join()\n",
    "        self.flush()\n",
    "#         self.out.release()\n",
    "        \n",
    "    def close(self):\n",
    "        self.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260 images found\n",
      "Using  2260 images\n",
      "demo image file: /media/golden/72FFC6EE48B5CF39/drone_tracking/other-tracking/raw_frames/DJI_0002/DJI_0002_0.jpg\n"
     ]
    }
   ],
   "source": [
    "image_folder = '/media/golden/72FFC6EE48B5CF39/drone_tracking/other-tracking/raw_frames/DJI_0002' \n",
    "\n",
    "image_files = glob.glob(image_folder + '/*.jpg')\n",
    "# image_files = glob.glob(image_folder + '*')\n",
    "image_files.sort(key=lambda file: int(file.split('.')[-2].split('_')[-1]))\n",
    "#positions_folder = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/test-frame/'\n",
    "positions_folder = '/media/golden/72FFC6EE48B5CF39/drone_tracking/other-tracking/processed_videos' \n",
    "positions_folder = os.path.join(positions_folder, os.path.basename(image_folder))\n",
    "\n",
    "print(len(image_files), 'images found')\n",
    "\n",
    "first_frame = 0\n",
    "last_frame = None\n",
    "label_every_n_frames = 1\n",
    "\n",
    "use_heads = False\n",
    "use_drone_movement = False\n",
    "use_class_color = False\n",
    "\n",
    "image_files = image_files[first_frame:last_frame:label_every_n_frames]\n",
    "print('Using ', len(image_files), 'images')\n",
    "print('demo image file:', image_files[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame width:  3840\n",
      "frame height:  2160\n"
     ]
    }
   ],
   "source": [
    "image_demo = Image.open(image_files[0])\n",
    "frame_width, frame_height = image_demo.size\n",
    "print('frame width: ', frame_width)\n",
    "print('frame height: ', frame_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VideoWriter at 0x7fe223142ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_video_file = '/media/golden/72FFC6EE48B5CF39/drone_tracking/other-tracking/DJI_0002'\n",
    "os.makedirs(new_video_file, exist_ok=True)\n",
    "# new_video_file = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/long-buffalo-tracked' \n",
    " \n",
    "video_writer = VideoWriter(frame_width=frame_width, frame_height=frame_height, video_out_file=new_video_file)\n",
    "video_writer.start()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#size of dot over animal in video\n",
    "dot_radius = 4\n",
    "dot_radius_head = 4\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# boxes_file = os.path.join(positions_folder, 'boxes.npy')\n",
    "classes_file = os.path.join(positions_folder, 'localizations/classes.npy')\n",
    "# scores_file = os.path.join(positions_folder, 'scores.npy')\n",
    "positions_file = os.path.join(positions_folder, 'localizations/positions.npy')\n",
    "if use_heads:\n",
    "    head_positions_file = os.path.join(positions_folder, 'localizations/head-positions.npy')\n",
    "# labeled_positions_file = os.path.join(positions_folder, 'labeled-positions.npy')\n",
    "labeled_positions_file = os.path.join(positions_folder, 'localizations/tracks.npy')\n",
    "if use_drone_movement:\n",
    "    drone_movement_file = os.path.join(positions_folder, 'localizations/drone_movement.npy')\n",
    "\n",
    "# boxes_list = np.squeeze(np.load(boxes_file))\n",
    "classes_list = np.squeeze(np.load(classes_file))\n",
    "# scores_list = np.squeeze(np.load(scores_file))\n",
    "positions_list = np.squeeze(np.load(positions_file))\n",
    "if use_heads:\n",
    "    head_positions_list = np.squeeze(np.load(head_positions_file))\n",
    "\n",
    "track_list = np.squeeze(np.load(labeled_positions_file))\n",
    "if use_drone_movement:\n",
    "    drone_movement_list = np.load(drone_movement_file)\n",
    "    drone_movement_list = np.squeeze(drone_movement_list)\n",
    "\n",
    "    print(len(drone_movement_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  processed\n",
      "200  processed\n",
      "400  processed\n",
      "600  processed\n",
      "800  processed\n",
      "1000  processed\n",
      "1200  processed\n",
      "1400  processed\n",
      "1600  processed\n",
      "1800  processed\n",
      "stopping\n",
      "2000  processed\n",
      "2200  processed\n",
      "done\n",
      "stopping\n",
      "time:  255.84150624275208\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#create then initialize the image reader queue\n",
    "image_reader = ImageReader(image_files, queue_size=1000)\n",
    "image_reader.start()\n",
    "\n",
    "point_trail = 150\n",
    "\n",
    "\n",
    "colors = [(230, 25, 75),(255, 225, 25),(0, 130, 200),(245, 130, 48),(145, 30, 180),\n",
    "          (70, 240, 240),(240, 50, 230),(210, 245, 60),(250, 190, 190),(0, 128, 128),\n",
    "          (230, 190, 255), (170, 110, 40), (255, 250, 200), (128, 0, 0), (170, 255, 195),\n",
    "          (128, 128, 0), (255, 215, 180), (0, 0, 128), (128, 128, 128), (255, 255, 255),\n",
    "          (0, 0, 0), (60, 180, 75)] \n",
    "          \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for frame_num, positions in enumerate(positions_list):\n",
    "    frame_num = frame_num + int(first_frame / label_every_n_frames)\n",
    "    if frame_num % 200 == 0:\n",
    "        print(frame_num, ' processed')\n",
    "    image_np, image_file = image_reader.read()\n",
    "    if image_np is None:\n",
    "        if self.verbose:\n",
    "            print('image failed to load: \\n' , image_path)\n",
    "        continue\n",
    "        \n",
    "    mod_point_trail = point_trail\n",
    "    if frame_num < point_trail:\n",
    "        mod_point_trail = frame_num\n",
    "    if use_drone_movement:\n",
    "        drone_comp = np.cumsum(\n",
    "            np.array(drone_movement_list[frame_num+1:frame_num-mod_point_trail:-1]), 0)\n",
    "        \n",
    "    for track_index, track in enumerate(track_list):\n",
    "            \n",
    "        \n",
    "        if track['first_frame'] > frame_num:\n",
    "            continue\n",
    "        track_step = frame_num - track['first_frame']\n",
    "        \n",
    "        #track is over for this step\n",
    "        if track_step > track['track'].shape[0]:\n",
    "            continue\n",
    "        \n",
    "        local_point_trail = point_trail\n",
    "        if local_point_trail > track_step:\n",
    "            local_point_trail = track_step\n",
    "        \n",
    "        position = track['track'][track_step - local_point_trail:track_step]\n",
    "        \n",
    "        track_class = track['class']\n",
    "        \n",
    "        if track_class == 0:\n",
    "            color = (255,0,255)\n",
    "        elif track_class == 1:\n",
    "            color = (0, 0, 255)\n",
    "        elif track_class == 2:\n",
    "            color = (255, 255, 0)\n",
    "        elif track_class == 3:\n",
    "            color = (0, 102, 204)\n",
    "        elif track_class == 4:\n",
    "            color = (0, 255, 255)\n",
    "        else:\n",
    "            color = (0, 0, 0)\n",
    "        if not use_class_color:\n",
    "            color = (0, 0, 255)\n",
    "        for step in range(position.shape[0]):\n",
    "            try:\n",
    "                if use_drone_movement:\n",
    "                    cv2.circle(image_np, (int(position[step][1] + drone_comp[position.shape[0] - step - 1][0]), \n",
    "                                          (frame_height - (int(position[step][0] - drone_comp[position.shape[0] - step - 1][1])))),\n",
    "                               dot_radius, colors[track_index%len(colors)], -1)\n",
    "                else:\n",
    "                    cv2.circle(image_np, (int(position[step][1]), \n",
    "                                          (frame_height - (int(position[step][0])))),\n",
    "                               dot_radius, colors[track_index%len(colors)], -1)\n",
    "\n",
    "#                 cv2.circle(image_np, (int(position[step][1]), \n",
    "#                                       (frame_height - (int(position[step][0])))),\n",
    "#                            dot_radius, colors[track_index%len(colors)], -1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(position.shape[0] - step - 1)\n",
    "                print(position.shape[0])\n",
    "                print('frame: ', frame_num, 'error drawing track point')\n",
    "            \n",
    "#         try:\n",
    "#             cv2.circle(image_np, (int(track['head'][track_step][1]), \n",
    "#                                   (frame_height - int(track['head'][track_step][0]))), dot_radius_head, color, -1)\n",
    "#         except:\n",
    "#             print('frame: ', frame_num, 'error drawing head')\n",
    "#             pass\n",
    "        if use_heads:\n",
    "            try:\n",
    "                head_vector = track['head'][track_step] - track['track'][track_step]\n",
    "\n",
    "                vec_mag = np.sqrt(head_vector[0] ** 2 +  head_vector[1] ** 2)\n",
    "                head_vector = head_vector / vec_mag\n",
    "\n",
    "                point0 = (int(track['head'][track_step][1]), (frame_height - int(track['head'][track_step][0])))\n",
    "                point1 = (int(track['head'][track_step][1] + 50 *head_vector[1]), \n",
    "                          (frame_height - int(track['head'][track_step][0] + 50*head_vector[0])))\n",
    "\n",
    "                cv2.line(image_np, point0, point1, color, 4, cv2.LINE_AA)\n",
    "            except:\n",
    "                print('frame: ', frame_num, 'error drawing head vector')\n",
    "                continue\n",
    "        \n",
    "#     for pos_index, position in enumerate(positions):\n",
    "        \n",
    "#         if classes_list[frame_num][pos_index] == 0:\n",
    "#             color = (0,0,255)\n",
    "#         elif classes_list[frame_num][pos_index] == 1:\n",
    "#             color = (0, 255, 0)\n",
    "#         elif classes_list[frame_num][pos_index] == 2:\n",
    "#             color = (255, 0, 0)\n",
    "#         else:\n",
    "#             color = (100, 100, 100)\n",
    "#         cv2.circle(image_np, (int(position[1]), (frame_height - int(position[0]))), dot_radius, color, -1)\n",
    "#         cv2.circle(image_np, (int(head_positions_list[frame_num][pos_index][1]), \n",
    "#                               (frame_height - int(head_positions_list[frame_num][pos_index][0]))), dot_radius_head, (0,140,255), -1)\n",
    "\n",
    "    #Change the file names so that they are properly numerically labeled every though may not be processing\n",
    "    #every frame\n",
    "    head, tail = os.path.split(image_file)\n",
    "    tail = tail.split('_')\n",
    "    new_tail = ''\n",
    "    for tail_part in tail[:-1]:\n",
    "        new_tail = new_tail + tail_part + '_'\n",
    "    new_tail = new_tail + ('{0:04d}.jpg').format(frame_num)\n",
    "    new_image_file = os.path.join(head, new_tail)\n",
    "    video_writer.add_frame([image_np, new_image_file])\n",
    "print('done')\n",
    "video_writer.stop()   \n",
    "cv2.destroyAllWindows()  \n",
    "print('time: ', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a video, run the following script in the images folder:\n",
    "\n",
    "ffmpeg -famerate 30 -i image-name%04d.jpg video-name.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VideoWriter' object has no attribute 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c65738d33f29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4df94bb60e49>\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopping'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VideoWriter' object has no attribute 't'"
     ]
    }
   ],
   "source": [
    "video_writer.stop()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_list[0]['track'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769 3372\n",
      "1678 3207\n",
      "1407 2637\n",
      "1455 3002\n",
      "1653 2925\n",
      "1002 2523\n",
      "1082 2065\n",
      "958 2308\n",
      "1423 2804\n",
      "841 2168\n",
      "1132 2427\n",
      "1048 2177\n",
      "1134 2559\n",
      "949 2193\n",
      "935 2193\n",
      "imshape (2160, 4096, 3)\n"
     ]
    }
   ],
   "source": [
    "for position in positions:\n",
    "    print((frame_height - int(position[0])), int(position[1]))\n",
    "print('imshape', image_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d40490f2ced44f98cc0101024292f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='x', max=30, min=-10), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "def f(x):\n",
    "    print(x)\n",
    "widgets.interact(f, x=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "drone_move = [[1,0],[1,1],[-1,0],[0,-1],[-1,1],[1,1],[-1,-1],[0,0],[0,0]]\n",
    "print(len(drone_move[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [-1 -1]\n",
      " [ 1  1]\n",
      " [-1  1]\n",
      " [ 0 -1]\n",
      " [-1  0]\n",
      " [ 1  1]]\n",
      "(8, 2)\n"
     ]
    }
   ],
   "source": [
    "frame_num = len(drone_move)\n",
    "mod_point_trail = len(drone_move)\n",
    "position = np.ones((9,2))\n",
    "step = 5\n",
    "# drone_comp = np.cumsum(np.array(drone_move[frame_num-5:frame_num-mod_point_trail:-1]), 0)\n",
    "a = np.array(drone_move[10:0:-1])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "drone_comp = np.cumsum(a, 0)\n",
    "\n",
    "# (int(position[step][1]) + drone_comp[position.shape[0] - step][1],\n",
    "#  (frame_height - (int(position[step][0]) + drone_comp[position.shape[0] - step][0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [-1, -1],\n",
       "       [ 0,  0],\n",
       "       [-1,  1],\n",
       "       [-1,  0],\n",
       "       [-2,  0],\n",
       "       [-1,  1]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drone_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/golden/72FFC6EE48B5CF39/kenya-tracking/labeled_zebra_new/NOV08_2017_DJI_0117_0.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "folder = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/labeled_zebra_new' \n",
    "new_folder = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/zebra_labeled' \n",
    "files = os.listdir(folder)\n",
    "print(os.path.join(folder, files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num = []\n",
    "error = 0\n",
    "for file in files:\n",
    "    try:\n",
    "        newfile = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/real_this_time/NOV08_2017_DJI_' + str(int(int(file.split('.')[0].split('_')[-1])/2)) + '.jpg'\n",
    "        shutil.copyfile(os.path.join(folder, file), newfile)\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        print(e)\n",
    "        continue\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/golden/72FFC6EE48B5CF39/kenya-tracking/labeled_zebra_new_2/NOV08_2017_DJI_0117_70000.jpg\n",
      "/media/golden/72FFC6EE48B5CF39/kenya-tracking/labeled_zebra_new_2/NOV08_2017_DJI_0117_7352.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "value = 70000 \n",
    "digits = 2\n",
    "image_file = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/labeled_zebra_new_2/NOV08_2017_DJI_0117_7352.jpg'\n",
    "head, tail = os.path.split(image_file)\n",
    "tail = tail.split('_')\n",
    "new_tail = ''\n",
    "for tail_part in tail[:-1]:\n",
    "    new_tail = new_tail + tail_part + '_'\n",
    "new_tail = new_tail + ('{0:04d}.jpg').format(value)\n",
    "new_file = os.path.join(head, new_tail)\n",
    "\n",
    "print(new_file)\n",
    "print(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOV08_2017_DJI_0.jpg',\n",
       " 'NOV08_2017_DJI_5.jpg',\n",
       " 'NOV08_2017_DJI_50.jpg',\n",
       " 'NOV08_2017_DJI_500.jpg',\n",
       " 'NOV08_2017_DJI_5000.jpg',\n",
       " 'NOV08_2017_DJI_5001.jpg',\n",
       " 'NOV08_2017_DJI_5002.jpg',\n",
       " 'NOV08_2017_DJI_5003.jpg',\n",
       " 'NOV08_2017_DJI_5004.jpg',\n",
       " 'NOV08_2017_DJI_5005.jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
