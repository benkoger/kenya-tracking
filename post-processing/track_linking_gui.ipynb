{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SETUP\n",
    "\n",
    "# KEY FUNCTIONS:\n",
    "# next frame = right arrow key\n",
    "# previous frame = left arrow key\n",
    "# frame at beginning of blue track = \"b\"\n",
    "# frame at end of green (focal) track = \"g\"\n",
    "# next blue track = up arrow\n",
    "# previous blue track = down arrow\n",
    "# next green (focal) track = \".\" (same button as '>')\n",
    "# previous green (focal) = \",\" (same button as '<')\n",
    "# add point (automatically adds to end of current green track) = click anywhere on picture\n",
    "# remove point = 'delete/backspace' key\n",
    "# add blue track to end of green track = space bar\n",
    "# permanently remove blue track = \"-\" \n",
    "\n",
    "#THINGS FOR USER TO ADD:\n",
    "#put them as strings - for example: '/Users/dbasili/koger_drive/long-buffalo-data/positions.npy'\n",
    "animal_type = 'GZ'\n",
    "video_name = 'observation061'\n",
    "\n",
    "\n",
    "positions_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/scare-clips/' + animal_type + '/' + video_name + '/localizations/positions.npy'      #the dots marking the animals on each frame\n",
    "scores_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/scare-clips/' + animal_type + '/' + video_name + '/localizations/scores.npy'\n",
    "tracks_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/scare-clips/' + animal_type + '/' + video_name + '/localizations/tracks.npy'            #file containing info about the tracks\n",
    "picture_folder_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/raw-frames/scare-clips/*/' + video_name + '/*jpg'   #folder with the pictures\n",
    "\n",
    "positions_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/' + video_name + '/localizations/positions.npy'      #the dots marking the animals on each frame\n",
    "scores_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/' + video_name + '/localizations/scores.npy'\n",
    "tracks_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/' + video_name + '/localizations/tracks.npy'            #file containing info about the tracks\n",
    "picture_folder_path = '/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/raw-frames/raw-footage/' + video_name + '/*/*jpg'   #folder with the pictures\n",
    "\n",
    "factor = 0.9                                                   #how much you want to shrink the original image\n",
    "skip = 1                                                         #how many frames you want to skip\n",
    "show_all_tracks = True\n",
    "\n",
    "#import\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59975\n"
     ]
    }
   ],
   "source": [
    "print(len(glob.glob(picture_folder_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSES       \n",
    "        \n",
    "def sort_by_last_frame(item):\n",
    "    return item['last_frame']\n",
    "\n",
    "def sort_by_first_frame(item):\n",
    "    return item['first_frame']\n",
    "\n",
    "#class for the window\n",
    "class Window():\n",
    "    \n",
    "    #constructor\n",
    "    def __init__(self, positions_path, tracks_path, picture_folder_path, factor):\n",
    "        self.positions_path = positions_path\n",
    "        self.tracks_path = tracks_path\n",
    "        if os.path.isfile(positions_path):\n",
    "            self.listofpositions = np.load(positions_path)\n",
    "        else:\n",
    "            self.listofpositions = None\n",
    "        if os.path.isfile(scores_path):\n",
    "            self.scores = np.load(scores_path)\n",
    "        else:\n",
    "            self.scores = None\n",
    "        # work on a copy of the tracks info.  Don't edit the original \n",
    "        self.listoftracks = np.ndarray.tolist(copy.deepcopy(np.load(tracks_path)))\n",
    "        # Focal tracks will only be sorted once\n",
    "        # Use case is start from first frame and build the track to the end\n",
    "        self.focal_tracks = copy.copy(self.listoftracks)\n",
    "        self.focal_tracks.sort(key=sort_by_first_frame)\n",
    "        self.listoftracks.sort(key=sort_by_first_frame)\n",
    "        # only do something on key release\n",
    "        # so only act when key press was something but now released\n",
    "        self.key_press = None\n",
    "            \n",
    "\n",
    "        for track in self.listoftracks:\n",
    "            track['connected'] = []\n",
    "            track['remove'] = False\n",
    "        self.files = glob.glob(picture_folder_path)\n",
    "        print('number of files', len(self.files))\n",
    "        self.files.sort(key=lambda file: (file.split('_')[-4], file.split('_')[-2], int(file.split('.')[-2].split('_')[-1])))\n",
    "        self.factor = factor\n",
    "        image = cv2.imread(self.files[0]) #to get size\n",
    "        self.h = int(np.size(image,0)*factor)\n",
    "        self.w = int(np.size(image,1)*factor)\n",
    "        self.full_pic = np.zeros((int(self.h+self.h/12),self.w,3), dtype=np.uint8)\n",
    "        self.focaltrackcount = 0\n",
    "        self.trackcount = 1\n",
    "        self.framecount = 0\n",
    "        n = self.focal_tracks[0]['last_frame'] #to get good frame\n",
    "        if n >= len(self.files) / skip:\n",
    "            self.framecount = int(len(self.files) / skip) - 1\n",
    "        else:\n",
    "            self.framecount = n\n",
    "        self.num_corrections = 0\n",
    "        \n",
    "        self.tracks_stack = []\n",
    "    \n",
    "    # call after every track change and will deal with saving at the correct user specified times\n",
    "    def save(self, save_type='passive'):\n",
    "        # How many save files to create\n",
    "        save_n_copies = 2\n",
    "        # How often to save after making corrections\n",
    "        save_every_n_corrections = 10\n",
    "        if self.num_corrections % save_every_n_corrections == 0 or save_type=='active':\n",
    "            if save_type == 'passive':\n",
    "                file_name = (os.path.splitext(self.tracks_path)[0] + '-' +\n",
    "                             str(self.num_corrections / save_every_n_corrections % save_n_copies) + '.npy')\n",
    "            else:\n",
    "                file_name = (os.path.splitext(self.tracks_path)[0] + '-' +\n",
    "                             'final.npy')\n",
    "            np.save(file_name, self.listoftracks)\n",
    "\n",
    "            print('saved at', file_name)\n",
    "        self.num_corrections += 1\n",
    "    \n",
    "    #draw points on image\n",
    "    def draw_points(self, picture, listofpositions, color1,color2,color3, r):\n",
    "        for i in listofpositions:\n",
    "            cv2.circle(picture, (int(i[1]), np.size(picture,0) - int(i[0])), r, (color1,color2,color3), -1)\n",
    "\n",
    "    #to process clicking on a button\n",
    "    def clicked(self, event, x, y, flags, param):\n",
    "        \n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            # Create new track at point where user clicks if they press shift key while clicking\n",
    "            if flags & cv2.EVENT_FLAG_SHIFTKEY:\n",
    "                self.update_stack()\n",
    "                x = int((1/self.factor) * x) #to adjust for picture\n",
    "                y = int((1/self.factor) * self.h - (1/self.factor) * y) #to adjust for picture\n",
    "                track = np.array([[y, x]])\n",
    "                pos_index = np.array([[np.nan]])\n",
    "                new_track_dict = self._create_new_track(self.framecount, track, pos_index, class_label=None)\n",
    "                first_frame_array =  np.array([track['first_frame'] for track in self.focal_tracks])\n",
    "                new_track_ind = np.searchsorted(first_frame_array, self.framecount)\n",
    "                self.focal_tracks.insert(new_track_ind, new_track_dict)\n",
    "                self.listoftracks.append(new_track_dict)\n",
    "                self.focaltrackcount = new_track_ind\n",
    "\n",
    "                self.listoftracks.sort(key=sort_by_first_frame)\n",
    "\n",
    "                self.save()\n",
    "            else:\n",
    "                self.add_point(x,y)\n",
    "\n",
    "    #to draw window\n",
    "    def draw_window(self):\n",
    "        image = cv2.imread(self.files[skip * self.framecount]) #read image - skipping frames\n",
    "        point_size = 2\n",
    "        track_length = 40\n",
    "        #lines for scale\n",
    "        cv2.line(image, (100,60),(110,60), (130,0,75), point_size*2) \n",
    "        cv2.line(image, (100,100),(150,100), (130,0,75), point_size*2) \n",
    "        cv2.line(image, (100,140),(200,140), (130,0,75), point_size*2)\n",
    "        #draw positions in the current frame\n",
    "        if self.listofpositions is not None:\n",
    "            positions = self.listofpositions[self.framecount][np.where(self.scores[self.framecount] > .97)]\n",
    "            self.draw_points(image, positions, 0,0,255, point_size*3)\n",
    "        # show segments of all active tracks in the current frame\n",
    "        if show_all_tracks:\n",
    "            for track in self.listoftracks:\n",
    "                if track['first_frame'] < self.framecount and track['first_frame'] + len(track['track']) > self.framecount:\n",
    "                    relative_frame = self.framecount - track['first_frame']\n",
    "                    if relative_frame - track_length // 2 < 0:\n",
    "                        track_show = track['track'][:relative_frame+int(track_length/2)]\n",
    "                    else:\n",
    "                        track_show = track['track'][relative_frame-int(track_length/2):relative_frame+int(track_length/2)]\n",
    "                    self.draw_points(image, track_show, 0,0,0, int(point_size / 2)) # draw focal track\n",
    "                    \n",
    "        # draw circle around focal track\n",
    "        point = self.focal_tracks[self.focaltrackcount]['track'][-1,:]\n",
    "        cv2.circle(image, (int(point[1]), int(image.shape[0] - point[0])), 50, (50, 0, 200), 1)\n",
    "        \n",
    "        rel_framecount = self.framecount - self.focal_tracks[self.focaltrackcount]['first_frame']\n",
    "        if rel_framecount >= 0:\n",
    "            self.draw_points(image, self.focal_tracks[self.focaltrackcount]['track'][:rel_framecount], 20,255,255, int(point_size/2)) # draw focal track\n",
    "            self.draw_points(image, self.focal_tracks[self.focaltrackcount]['track'][rel_framecount:], 255,255,200, int(point_size/2)) # draw focal track\n",
    "            self.draw_points(image, self.focal_tracks[self.focaltrackcount]['track'][rel_framecount:rel_framecount+1], 102, 0, 51, point_size*2)\n",
    "        self.draw_points(image, self.listoftracks[self.trackcount]['track'], 255,0,0, int(point_size/2)) # draw new track\n",
    "        #show where the new track starts\n",
    "        self.draw_points(image, self.listoftracks[self.trackcount]['track'][:1], 255,144,30, point_size*2) # draw new track\n",
    "        rel_frame_new_track = self.framecount - self.listoftracks[self.trackcount]['first_frame']\n",
    "        # The potential new track starts before the current frame\n",
    "        if rel_frame_new_track > 0:\n",
    "            # The potential new track ends after the current frame\n",
    "            if self.listoftracks[self.trackcount]['first_frame'] + len(self.listoftracks[self.trackcount]['track']) > self.framecount:\n",
    "                current_point = self.listoftracks[self.trackcount]['track'][rel_frame_new_track]\n",
    "                self.draw_points(image, [current_point], 181,186,10, point_size*2)\n",
    "        new_pic = cv2.resize(image, (self.w, self.h))\n",
    "        self.full_pic[0:self.h,0:self.w] = new_pic[0:self.h,0:self.w] #put onto frame\n",
    "        frame_diff = self.listoftracks[self.trackcount]['first_frame'] - self.framecount\n",
    "        font_color = (255, 255, 255)\n",
    "        text_size = 1\n",
    "        text_spacing = 400\n",
    "        text_row = 40\n",
    "        cv2.putText(self.full_pic, 'frames ahead: %d'%frame_diff, (self.w-text_spacing, text_row), \n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.putText(self.full_pic, 'current frame: %d'%self.framecount, (self.w-text_spacing*2, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.putText(self.full_pic, 'current track: %d'%self.focaltrackcount, (self.w-text_spacing*3, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        diff_between_tracks = (self.listoftracks[self.trackcount]['track'][0, :] - \n",
    "                               self.focal_tracks[self.focaltrackcount]['track'][-1, :])\n",
    "        dist_to_next = np.sqrt(np.sum((diff_between_tracks) ** 2))\n",
    "        cv2.putText(self.full_pic, 'dist: %d'%dist_to_next, (self.w-text_spacing*4, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.putText(self.full_pic, 'TFF: %d'%len(self.listoftracks), (self.w-text_spacing*5, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.putText(self.full_pic, 'focal first frame: %d'%self.focal_tracks[self.focaltrackcount]['first_frame'], \n",
    "                    (self.w-text_spacing * 6, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.putText(self.full_pic, 'focal length: %d'%len(self.focal_tracks[self.focaltrackcount]['track']), \n",
    "                    (self.w-text_spacing * 7, text_row),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, text_size, font_color, 1, cv2.LINE_AA)\n",
    "        cv2.imshow('pic0', self.full_pic)\n",
    "        \n",
    "    # Stack of previous states so action can be undone \n",
    "    def update_stack(self):\n",
    "        self.tracks_stack.append(\n",
    "            [copy.deepcopy(self.listoftracks), copy.deepcopy(self.focal_tracks), copy.deepcopy(self.listofpositions)])\n",
    "        # 10 is number of previous states to store\n",
    "        if len(self.tracks_stack) > 10:\n",
    "            del self.tracks_stack[0]\n",
    "            \n",
    "    def update_listoftracks(self):\n",
    "        self.listoftracks = copy.copy(self.focal_tracks)\n",
    "        self.listoftracks.sort(key=sort_by_first_frame)\n",
    "    \n",
    "    def update_focal_tracks(self):\n",
    "        self.focal_tracks = copy.copy(self.listoftracks)\n",
    "        self.focal_tracks.sort(key=sort_by_first_frame)\n",
    "        \n",
    "    def record_new_point(self, point, frame):\n",
    "        self.listofpositions[frame] = np.vstack([self.listofpositions[frame], point])\n",
    "            \n",
    "    # add a point to picture and to current track\n",
    "    def add_point(self, x, y):\n",
    "        focal_track = self.focal_tracks[self.focaltrackcount]\n",
    "        self.update_stack()\n",
    "        x = int((1/self.factor) * x) #to adjust for picture\n",
    "        y = int((1/self.factor) * self.h - (1/self.factor) * y) #to adjust for picture\n",
    "        frame_dif = self.framecount - focal_track['last_frame']\n",
    "        x_diff = x - focal_track['track'][-1, 1]\n",
    "        y_diff = y - focal_track['track'][-1, 0]\n",
    "        if frame_dif != 0:\n",
    "            position_dif_step = [y_diff / frame_dif, x_diff / frame_dif]\n",
    "        for frame in range(frame_dif):\n",
    "            focal_track['track'] = np.vstack([focal_track['track'], focal_track['track'][-1,:] + position_dif_step])\n",
    "            nan = np.empty((1,1))\n",
    "            nan[:] = np.nan\n",
    "            focal_track['pos_index'] = np.vstack([focal_track['pos_index'], nan])\n",
    "            focal_track['last_frame'] += 1\n",
    "            \n",
    "        self.focal_tracks[self.focaltrackcount]['connected'].append(len(self.focal_tracks[self.focaltrackcount]['track']))\n",
    "        self.update_listoftracks()\n",
    "        self.find_next_track()\n",
    "        self.draw_window()\n",
    "        self.save()\n",
    "        print('adding point')\n",
    "        \n",
    "        \n",
    "\n",
    "    #find a good track to go to, given the focal track\n",
    "    def find_next_track(self):\n",
    "        last_seen = self.focal_tracks[self.focaltrackcount]['last_frame']\n",
    "        for track_ind, track in enumerate(self.listoftracks): #make trackcount above 0\n",
    "            frame_diff = track['first_frame'] - last_seen\n",
    "            if frame_diff >= 0:\n",
    "                self.trackcount = track_ind \n",
    "                break\n",
    "        self.trackcount = track_ind\n",
    "\n",
    "    #to help have keyboard shortcuts\n",
    "    def detect_keys(self, key):\n",
    "#         print(key)\n",
    "#         if key != 255:\n",
    "#             print(key)\n",
    "        # Scroll through frames by just holding down arrow keys\n",
    "        #if key == 3 or key == 83: #right key = move frame forward\n",
    "\n",
    "        if key == ord(';'):\n",
    "            self.change_frame_function(3)\n",
    "        #elif key == 2 or key == 81: #left key = move frame back\n",
    "        elif key == ord('k'):\n",
    "            self.change_frame_function(-3)\n",
    "        elif key == ord(']'):\n",
    "            self.change_frame_function(1)\n",
    "        #elif key == 2 or key == 81: #left key = move frame back\n",
    "        elif key == ord('['):\n",
    "            self.change_frame_function(-1)\n",
    "        elif key == ord('9'):\n",
    "            self.change_frame_function(-90)\n",
    "        #elif key == 2 or key == 81: #left key = move frame back\n",
    "        elif key == ord('0'):\n",
    "            self.change_frame_function(90)\n",
    "        elif key == 58:\n",
    "            self.change_frame_function(3)\n",
    "        elif key == ord('x'):\n",
    "            self.change_frame_function(30)\n",
    "        elif key == ord('z'):\n",
    "            self.change_frame_function(-30)\n",
    "        # only do the following thing on the key release\n",
    "        elif key == 255 and self.key_press:\n",
    "            key = self.key_press\n",
    "            self.key_press = None\n",
    "#             print('here ', key, ' : ', self.key_press)\n",
    "#             if key == 0 or key == 82: #up key = move track forward\n",
    "            if key == ord('o'):\n",
    "                self.next_track_function()\n",
    "#             elif key == 1 or key == 84: #down key = move track back\n",
    "            elif key == ord('l'):\n",
    "                self.back_track_function()\n",
    "            elif key == ord('.'): # . key = move focal track forward\n",
    "                self.next_focal_track_function()\n",
    "            elif key == ord(','): # , key = move focal track back\n",
    "                self.back_focal_track_function()\n",
    "#             elif key == 127: #delete key = delete point\n",
    "#                 self.remove_point_function()\n",
    "            elif key == 32: #space key = add to track\n",
    "                self.add_to_track_function()\n",
    "            elif key == 45: # - key = remove track\n",
    "                self.delete_focal_track()\n",
    "            elif key == ord('g'): # 'g' key = green function\n",
    "                self.green_function()\n",
    "            elif key == ord('b'): # 'b' key = blue function\n",
    "                self.blue_function()\n",
    "            elif key == ord('s'): # 's' key = split focal path\n",
    "                self.split_track('focal')\n",
    "            elif key == ord('a'):\n",
    "                self.split_track('added')\n",
    "            elif key == ord('u'): # undo function\n",
    "                self.undo()\n",
    "            \n",
    "            \n",
    "                \n",
    "        else:\n",
    "            self.key_press = key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #functions for buttons\n",
    "    def change_frame_function(self, increment):\n",
    "        n = self.framecount + increment\n",
    "        if n < len(self.files)/skip and n >= 0:\n",
    "            self.framecount = n\n",
    "        self.draw_window()\n",
    "        \n",
    "    def next_track_function(self):\n",
    "        n = self.trackcount + 1\n",
    "        if n < len(self.listoftracks) and n >= 0:\n",
    "            self.trackcount = n\n",
    "        self.draw_window()\n",
    "\n",
    "    def back_track_function(self):\n",
    "        n = self.trackcount - 1\n",
    "        if n < len(self.listoftracks) and n >= 0:\n",
    "            self.trackcount = n\n",
    "        self.draw_window()\n",
    "        \n",
    "    def undo(self):\n",
    "        if self.tracks_stack:\n",
    "            old_tracks = self.tracks_stack.pop()\n",
    "            self.listoftracks = old_tracks[0]\n",
    "            self.focal_tracks = old_tracks[1]\n",
    "            self.listofpositions = old_tracks[2]\n",
    "            self.draw_window()\n",
    "            print('undoing last action...')\n",
    "        else:\n",
    "            print('Can not undo any more')\n",
    "\n",
    "    def next_focal_track_function(self):\n",
    "        #check that doesn't go out of bounds\n",
    "        n1 = self.focaltrackcount + 1\n",
    "        if n1 < len(self.focal_tracks) and n1 >= 0:\n",
    "            self.focaltrackcount = n1\n",
    "        #to next get good next potential track\n",
    "        n = self.focal_tracks[self.focaltrackcount]['last_frame'] \n",
    "        if n >= len(self.files) / skip:\n",
    "            self.framecount = int(len(self.files) / skip) - 1\n",
    "        else:\n",
    "            self.framecount = n\n",
    "        self.find_next_track() #make blue track start after green track ends\n",
    "        self.draw_window()\n",
    "\n",
    "    def back_focal_track_function(self):\n",
    "        #check that doesn't go out of bounds\n",
    "        n1 = self.focaltrackcount - 1\n",
    "        if n1 < len(self.focal_tracks) and n1 >= 0:\n",
    "            self.focaltrackcount = n1\n",
    "        #to get good frame\n",
    "        n = self.focal_tracks[self.focaltrackcount]['last_frame']\n",
    "        if n >= len(self.files)/skip:\n",
    "            self.framecount = int(len(self.files)/skip) - 1\n",
    "        else:\n",
    "            self.framecount = n\n",
    "        self.find_next_track() #make blue track start after green track ends\n",
    "        self.draw_window()\n",
    "        \n",
    "    \n",
    "    def delete_focal_track(self):\n",
    "        self.update_stack()\n",
    "#         self.focal_tracks[self.focaltrackcount]['remove'] = True\n",
    "        del self.focal_tracks[self.focaltrackcount]\n",
    "        if self.focaltrackcount >= len(self.focal_tracks):\n",
    "            self.focaltrackcount = len(self.focal_tracks) - 1 \n",
    "        self.update_listoftracks()\n",
    "        self.find_next_track()\n",
    "        self.draw_window()\n",
    "        self.save()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def add_to_track_function(self):\n",
    "        try:\n",
    "            self.update_stack()\n",
    "            if self.focal_tracks[self.focaltrackcount]['first_frame'] <= self.listoftracks[self.trackcount]['first_frame']:\n",
    "                focal_track = self.focal_tracks[self.focaltrackcount]\n",
    "                added_track = self.listoftracks[self.trackcount]\n",
    "                focal_list = self.focal_tracks\n",
    "                added_list = self.listoftracks\n",
    "                focal_index = self.focaltrackcount\n",
    "                added_index = self.trackcount\n",
    "            else:\n",
    "                added_track = self.focal_tracks[self.focaltrackcount]\n",
    "                focal_track = self.listoftracks[self.trackcount]\n",
    "                added_list = self.focal_list\n",
    "                focal_list = self.listoftracks\n",
    "                added_index = self.focaltrackcount\n",
    "                focal_index = self.trackcount\n",
    "                print('flipped')\n",
    "            if focal_track is added_track: #make sure isn't same as focal track\n",
    "                pass\n",
    "            else:\n",
    "                # record where new points are added\n",
    "                focal_track['connected'].append(focal_track['track'].shape[0]) \n",
    "                # it is possible that the second track starts before the first one ends\n",
    "                # default behavior:\n",
    "                # use the part from the added track\n",
    "                # linear interpolation when there is a gap between tracks\n",
    "                # otherwise just join\n",
    "                # overlap = (focal_track['first_frame'] + focal_track['track'].shape[0]) - added_track['first_frame'] # should: focal_track['first_frame'] + focal_track['track'].shape[0] = 'last_frame\n",
    "                overlap = focal_track['last_frame'] - added_track['first_frame'] + 1\n",
    "                if overlap > 0:\n",
    "                    # added track is completely overlapping with focal track\n",
    "                    if focal_track['last_frame'] >= added_track['last_frame']:\n",
    "                        first_frame = added_track['first_frame'] - focal_track['first_frame']\n",
    "                        last_frame = added_track['last_frame'] - focal_track['first_frame'] + 1\n",
    "                        focal_track['track'][first_frame:last_frame] = added_track['track']\n",
    "                        focal_track['pos_index'][first_frame:last_frame] = added_track['pos_index']\n",
    "                    # added track extends beyond focal track\n",
    "                    else:\n",
    "                        focal_track['track'] = np.vstack([focal_track['track'][:-overlap], added_track['track']])\n",
    "                        focal_track['pos_index'] = np.vstack([focal_track['pos_index'][:-overlap], added_track['pos_index']])\n",
    "                        focal_track['last_frame'] = added_track['last_frame']\n",
    "                # there is a gap betwen tracks\n",
    "                elif overlap <= -1:\n",
    "                    position_dif = added_track['track'][0, :] - focal_track['track'][-1, :]\n",
    "                    # +1 because one dot needs two steps\n",
    "                    position_dif_step = position_dif / (-1 * overlap + 1)\n",
    "                    for step in range(-1 * (overlap)):\n",
    "                        focal_track['track'] = np.vstack([focal_track['track'], focal_track['track'][-1,:] + position_dif_step])\n",
    "                        nan = np.empty((1,1))\n",
    "                        nan[:] = np.nan\n",
    "                        focal_track['pos_index'] = np.vstack([focal_track['pos_index'], nan])\n",
    "                    focal_track['track'] = np.vstack([focal_track['track'], added_track['track']])\n",
    "                    focal_track['pos_index'] = np.vstack([focal_track['pos_index'], added_track['pos_index']])\n",
    "                    focal_track['last_frame'] = added_track['last_frame']\n",
    "                # perfect alignment\n",
    "                else:\n",
    "                    focal_track['track'] = np.vstack([focal_track['track'], added_track['track']])\n",
    "                    focal_track['pos_index'] = np.vstack([focal_track['pos_index'], added_track['pos_index']])\n",
    "                    focal_track['last_frame'] = added_track['last_frame']\n",
    "                assert (focal_track['first_frame'] + len(focal_track['track']) - 1 == focal_track['last_frame']), \"track length doesn't fit with last_frame value\"\n",
    "                added_track['remove'] = True\n",
    "                for track_ind, track in enumerate(focal_list):\n",
    "                    if track['remove']:\n",
    "                        print('track merged')\n",
    "                        del focal_list[track_ind]\n",
    "                self.update_listoftracks()\n",
    "            self.find_next_track() #make blue track start after green track ends\n",
    "            self.draw_window()\n",
    "            self.save()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _create_new_track(self, first_frame, track, pos_index, class_label=None):\n",
    "        new_track = {'track': track,\n",
    "                    'first_frame': first_frame,\n",
    "                    'last_frame': first_frame + track.shape[0] - 1, \n",
    "                     'connected': [],\n",
    "                     'pos_index': pos_index,\n",
    "                     'remove': False,\n",
    "                     'class_label': [class_label]\n",
    "                    }\n",
    "\n",
    "        return new_track\n",
    "    \n",
    "        \n",
    "    def split_track(self, track_type):\n",
    "        self.update_stack()\n",
    "        if track_type == 'focal':\n",
    "            track = self.focal_tracks[self.focaltrackcount]\n",
    "            track_ind = self.focaltrackcount\n",
    "        elif track_type == 'added':\n",
    "            track = self.listoftracks[self.trackcount]\n",
    "            track_ind = self.trackcount\n",
    "        else:\n",
    "            raise NameError('not valid track type to print')\n",
    "            \n",
    "        # assumes the user is on the last frame of the old track\n",
    "        split_frame = self.framecount - track['first_frame'] + 1\n",
    "        new_track = copy.copy(track['track'][split_frame:])\n",
    "        new_pos_index = copy.copy(track['pos_index'][split_frame:])\n",
    "        # Older version had some tracks not have a class\n",
    "        try:\n",
    "            new_track_dict = self._create_new_track(self.framecount + 1, new_track, new_pos_index, track['class'])\n",
    "        except:\n",
    "            new_track_dict = self._create_new_track(self.framecount + 1, new_track, new_pos_index)\n",
    "\n",
    "        # get rid of the new track part from the old track\n",
    "        track['track'] = track['track'][:split_frame]\n",
    "        track['pos_index'] = track['pos_index'][:split_frame]\n",
    "        track['last_frame'] = self.framecount\n",
    "        self.listoftracks.append(new_track_dict)\n",
    "        self.focal_tracks.append(new_track_dict)\n",
    "        self.listoftracks.sort(key=sort_by_first_frame)\n",
    "        self.focal_tracks.sort(key=sort_by_first_frame)\n",
    "        self.save()\n",
    "        \n",
    "        \n",
    "\n",
    "    def blue_function(self):\n",
    "        n = self.listoftracks[self.trackcount]['first_frame'] #to get good frame\n",
    "        if n >= len(self.files)/skip:\n",
    "            self.framecount = int(len(self.files)/skip) - 1\n",
    "        else:\n",
    "            self.framecount = n\n",
    "        self.draw_window()\n",
    "\n",
    "    def green_function(self):\n",
    "        n = self.focal_tracks[self.focaltrackcount]['first_frame'] + len(self.focal_tracks[self.focaltrackcount]['track']) #to get good frame\n",
    "        if n >= len(self.files)/skip:\n",
    "            self.framecount = int(len(self.files)/skip) - 1\n",
    "        else:\n",
    "            self.framecount = n\n",
    "        self.draw_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files 59975\n",
      "track merged\n",
      "saved at /media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/observation061/localizations/tracks-0.0.npy\n",
      "track merged\n",
      "track merged\n",
      "track merged\n",
      "adding point\n",
      "adding point\n",
      "adding point\n",
      "track merged\n",
      "track merged\n",
      "track merged\n",
      "track merged\n",
      "saved at /media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/observation061/localizations/tracks-1.0.npy\n",
      "track merged\n",
      "saved at /media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed-videos/raw-footage/observation061/localizations/tracks-final.npy\n"
     ]
    }
   ],
   "source": [
    "#RUN\n",
    "\n",
    "#get good track, draw image on window, set mouse to work\n",
    "window = Window(positions_path, tracks_path, picture_folder_path, factor)\n",
    "\n",
    "window.find_next_track()\n",
    "window.draw_window()\n",
    "cv2.namedWindow('pic0')\n",
    "cv2.setMouseCallback('pic0', window.clicked)\n",
    "\n",
    "#loop to keep image updating\n",
    "while True:\n",
    "#     cv2.imshow('pic0', window.full_pic)\n",
    "    #stop loop if press 'x'\n",
    "    key = cv2.waitKey(2) & 0xff\n",
    "    window.detect_keys(key)\n",
    "    if key == 27:\n",
    "        window.save('active')\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_xy_list = copy.deepcopy(track_list)\n",
    "\n",
    "for track_ind, _ in enumerate(track_xy_list[:]):\n",
    "    track_xy_list[track_ind]['track'] = np.hstack([-track_xy_list[track_ind]['track'][:,1:], track_xy_list[track_ind]['track'][:,0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(window.listoftracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "tracks_path = '/media/golden/72FFC6EE48B5CF39/kenya-tracking/processed_videos/APR03_2018_C_DJI_0284/localizations/tracks.npy' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = np.load(tracks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_frame = [track['first_frame'] for track in tracks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.ones((10,2))\n",
    "y = np.ones((10,2)) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x == 10:\n",
    "    x = 5\n",
    "else:\n",
    "    print('here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.5,  5.5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [{'c': 10, 'k': 1}, {'c': 3, 'k': 2}, {'c': 5, 'k': 3}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy = copy.copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': 1, 'c': 10}, {'k': 2, 'c': 3}, {'k': 3, 'c': 5}]\n",
      "[{'k': 1, 'c': 10}, {'k': 2, 'c': 3}, {'k': 3, 'c': 5}]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort(item):\n",
    "    return item['c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy.sort(key=sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': 1, 'c': 10}, {'k': 2, 'c': 3}, {'k': 3, 'c': 5}]\n",
      "[{'k': 2, 'c': 3}, {'k': 3, 'c': 5}, {'k': 1, 'c': 10}]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy[0]['c'] = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_copy.append({'c':-13, 'k':-2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': 1, 'c': 10}, {'k': 2, 'c': -2}, {'k': 3, 'c': 5}]\n",
      "[{'k': 2, 'c': -2}, {'k': 3, 'c': 5}, {'k': 1, 'c': 10}, {'k': -2, 'c': -13}]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]['new'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'k': array([ 1.,  1.]), 'c': 5}]\n",
      "[{'k': 2, 'c': -2}, {'k': array([ 1.,  1.]), 'c': 5}, {'k': 1, 'new': 1000, 'c': 10}, {'k': -2, 'c': -13}]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(len(x_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.load('/media/golden/72FFC6EE48B5CF39/drone-tracking/kenya-tracking/processed_videos/APR03_2018_C_DJI_0284/localizations/positions.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "(1, 2)\n",
      "[[  8.05952515e+02   8.69874329e+02]\n",
      " [  7.42794312e+02   2.36526294e+03]\n",
      " [  9.41179443e+02   1.02659216e+03]\n",
      " [  9.67757202e+02   9.42120605e+02]\n",
      " [  9.32276245e+02   2.21676831e+03]\n",
      " [  7.97129028e+02   2.25654980e+03]\n",
      " [  1.04837268e+03   1.73531519e+03]\n",
      " [  8.93669312e+02   9.65061218e+02]\n",
      " [  9.70521851e+02   1.05232141e+03]\n",
      " [  6.90568604e+02   1.82026025e+03]\n",
      " [  8.29639893e+02   1.71730188e+03]\n",
      " [  7.89107910e+02   2.17300659e+03]\n",
      " [  1.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape)\n",
    "print(np.ones((1,2)).shape)\n",
    "print(np.vstack([x[0], np.ones((1,2))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
